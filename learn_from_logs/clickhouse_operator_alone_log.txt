I0611 06:09:22.880761       1 main.go:63] main.go:63:Run():start
I0611 06:09:22.880830       1 main.go:66] Run():Starting clickhouse-operator. Version:0.23.5 GitSHA:078df79 BuiltAt:2024-04-11T23:30:08
I0611 06:09:22.880928       1 thread_chi.go:50] thread_chi.go:50:initClickHouse():start
I0611 06:09:22.881147       1 config_manager.go:372] Parameters num: 11
I0611 06:09:22.881156       1 config_manager.go:374] OPERATOR_CONTAINER_CPU_LIMIT=10
I0611 06:09:22.881157       1 config_manager.go:374] OPERATOR_CONTAINER_CPU_REQUEST=0
I0611 06:09:22.881159       1 config_manager.go:374] OPERATOR_CONTAINER_MEM_LIMIT=10146668544
I0611 06:09:22.881160       1 config_manager.go:374] OPERATOR_CONTAINER_MEM_REQUEST=0
I0611 06:09:22.881162       1 config_manager.go:374] OPERATOR_POD_IP=10.244.0.17
I0611 06:09:22.881163       1 config_manager.go:374] OPERATOR_POD_NAME=clickhouse-operator-69f675cf8f-86j5s
I0611 06:09:22.881164       1 config_manager.go:374] OPERATOR_POD_NAMESPACE=test
I0611 06:09:22.881166       1 config_manager.go:374] OPERATOR_POD_NODE_NAME=local-control-plane
I0611 06:09:22.881167       1 config_manager.go:374] OPERATOR_POD_SERVICE_ACCOUNT=clickhouse-operator
I0611 06:09:22.881169       1 config_manager.go:374] WATCH_NAMESPACE=
I0611 06:09:22.881170       1 config_manager.go:374] WATCH_NAMESPACES=
I0611 06:09:22.881700       1 config_manager.go:91] File-based CHOP config:
I0611 06:09:22.882282       1 config_manager.go:92] 
runtime:
    configFilePath: /etc/clickhouse-operator/config.yaml
    configFolderPath: /etc/clickhouse-operator
    configCRNamespace: ""
    configCRName: ""
    configCRSources: []
    namespace: ""
watch:
    namespaces: []
clickhouse:
    configuration:
        file:
            path:
                common: config.d
                host: conf.d
                user: users.d
        user:
            default:
                profile: default
                quota: default
                networksIP:
                    - ::1
                    - 127.0.0.1
                password: '***'
        network:
            hostRegexpTemplate: (chi-{chi}-[^.]+\d+-\d+|clickhouse\-{chi})\.{namespace}\.svc\.cluster\.local$
    configurationRestartPolicy:
        rules:
            - version: '*'
              rules:
                - settings/*: "yes"
                - settings/access_control_path: "no"
                - settings/dictionaries_config: "no"
                - settings/max_server_memory_*: "no"
                - settings/max_*_to_drop: "no"
                - settings/max_concurrent_queries: "no"
                - settings/models_config: "no"
                - settings/user_defined_executable_functions_config: "no"
                - settings/logger/*: "no"
                - settings/macros/*: "no"
                - settings/remote_servers/*: "no"
                - settings/user_directories/*: "no"
                - zookeeper/*: "yes"
                - files/*.xml: "yes"
                - files/config.d/*.xml: "yes"
                - files/config.d/*dict*.xml: "no"
                - profiles/default/background_*_pool_size: "yes"
                - profiles/default/max_*_for_server: "yes"
            - version: 21.*
              rules:
                - settings/logger: "yes"
    access:
        scheme: auto
        secret:
            name: clickhouse-operator
            runtime:
                username: ""
                password: ""
                fetched: false
                error: ""
        port: 8123
        timeouts:
            connect: 1ns
            query: 4ns
    metrics:
        timeouts:
            collect: 9ns
template:
    chi:
        policy: ApplyOnNextReconcile
        path: templates.d
reconcile:
    runtime:
        reconcileCHIsThreadsNumber: 10
        reconcileShardsThreadsNumber: 5
        reconcileShardsMaxConcurrencyPercent: 50
        threadsNumber: 0
    statefulSet:
        create:
            onFailure: ignore
        update:
            timeout: 300
            pollInterval: 5
            onFailure: abort
    host:
        wait:
            exclude: "true"
            queries: "true"
            include: "false"
annotation:
    include: []
    exclude: []
label:
    include: []
    exclude: []
    appendScope: "no"
    runtime:
        appendScope: false
statefulSet:
    revisionHistoryLimit: 0
pod:
    terminationGracePeriod: 30
logger:
    logtostderr: "true"
    alsologtostderr: "false"
    v: "1"
    stderrthreshold: ""
    vmodule: ""
    log_backtrace_at: ""
watchNamespaces: []
chCommonConfigsPath: ""
chHostConfigsPath: ""
chUsersConfigsPath: ""
chiTemplatesPath: ""
statefulSetUpdateTimeout: 0
statefulSetUpdatePollPeriod: 0
onStatefulSetCreateFailureAction: ""
onStatefulSetUpdateFailureAction: ""
chConfigUserDefaultProfile: ""
chConfigUserDefaultQuota: ""
chConfigUserDefaultNetworksIP: []
chConfigUserDefaultPassword: '***'
chConfigNetworksHostRegexpTemplate: ""
chScheme: ""
chUsername: '***'
chPassword: '***'
chCredentialsSecretNamespace: ""
chCredentialsSecretName: ""
chPort: 0
logtostderr: ""
alsologtostderr: ""
v: ""
stderrthreshold: ""
vmodule: ""
log_backtrace_at: ""
reconcileThreadsNumber: 0
reconcileWaitExclude: false
reconcileWaitInclude: false
includeIntoPropagationAnnotations: []
excludeFromPropagationAnnotations: []
includeIntoPropagationLabels: []
excludeFromPropagationLabels: []
appendScopeLabels: ""
terminationGracePeriod: 0
revisionHistoryLimit: 0
I0611 06:09:22.882302       1 config_manager.go:131] getAllCRBasedConfigs():Looking for ClickHouseOperatorConfigurations in namespace 'test'.
I0611 06:09:22.885319       1 config_manager.go:414] Going to search for username/password in the secret 'test/clickhouse-operator'
I0611 06:09:22.886111       1 config_manager.go:431] Secret fetched: 'test/clickhouse-operator'
I0611 06:09:22.886120       1 config_manager.go:441] Password read from the secret: 'test/clickhouse-operator'
I0611 06:09:22.886123       1 config_manager.go:438] Username read from the secret: 'test/clickhouse-operator'
I0611 06:09:22.886125       1 config_manager.go:106] Unified CHOP config - with secret data fetched (but not post-processed yet):
I0611 06:09:22.886313       1 config_manager.go:107] 
runtime:
    configFilePath: /etc/clickhouse-operator/config.yaml
    configFolderPath: /etc/clickhouse-operator
    configCRNamespace: ""
    configCRName: ""
    configCRSources: []
    namespace: ""
watch:
    namespaces: []
clickhouse:
    configuration:
        file:
            path:
                common: config.d
                host: conf.d
                user: users.d
        user:
            default:
                profile: default
                quota: default
                networksIP:
                    - ::1
                    - 127.0.0.1
                password: '***'
        network:
            hostRegexpTemplate: (chi-{chi}-[^.]+\d+-\d+|clickhouse\-{chi})\.{namespace}\.svc\.cluster\.local$
    configurationRestartPolicy:
        rules:
            - version: '*'
              rules:
                - settings/*: "yes"
                - settings/access_control_path: "no"
                - settings/dictionaries_config: "no"
                - settings/max_server_memory_*: "no"
                - settings/max_*_to_drop: "no"
                - settings/max_concurrent_queries: "no"
                - settings/models_config: "no"
                - settings/user_defined_executable_functions_config: "no"
                - settings/logger/*: "no"
                - settings/macros/*: "no"
                - settings/remote_servers/*: "no"
                - settings/user_directories/*: "no"
                - zookeeper/*: "yes"
                - files/*.xml: "yes"
                - files/config.d/*.xml: "yes"
                - files/config.d/*dict*.xml: "no"
                - profiles/default/background_*_pool_size: "yes"
                - profiles/default/max_*_for_server: "yes"
            - version: 21.*
              rules:
                - settings/logger: "yes"
    access:
        scheme: auto
        secret:
            name: clickhouse-operator
            runtime:
                username: clickhouse_operator
                password: '***'
                fetched: true
                error: ""
        port: 8123
        timeouts:
            connect: 1ns
            query: 4ns
    metrics:
        timeouts:
            collect: 9ns
template:
    chi:
        policy: ApplyOnNextReconcile
        path: templates.d
reconcile:
    runtime:
        reconcileCHIsThreadsNumber: 10
        reconcileShardsThreadsNumber: 5
        reconcileShardsMaxConcurrencyPercent: 50
        threadsNumber: 0
    statefulSet:
        create:
            onFailure: ignore
        update:
            timeout: 300
            pollInterval: 5
            onFailure: abort
    host:
        wait:
            exclude: "true"
            queries: "true"
            include: "false"
annotation:
    include: []
    exclude: []
label:
    include: []
    exclude: []
    appendScope: "no"
    runtime:
        appendScope: false
statefulSet:
    revisionHistoryLimit: 0
pod:
    terminationGracePeriod: 30
logger:
    logtostderr: "true"
    alsologtostderr: "false"
    v: "1"
    stderrthreshold: ""
    vmodule: ""
    log_backtrace_at: ""
watchNamespaces: []
chCommonConfigsPath: ""
chHostConfigsPath: ""
chUsersConfigsPath: ""
chiTemplatesPath: ""
statefulSetUpdateTimeout: 0
statefulSetUpdatePollPeriod: 0
onStatefulSetCreateFailureAction: ""
onStatefulSetUpdateFailureAction: ""
chConfigUserDefaultProfile: ""
chConfigUserDefaultQuota: ""
chConfigUserDefaultNetworksIP: []
chConfigUserDefaultPassword: '***'
chConfigNetworksHostRegexpTemplate: ""
chScheme: ""
chUsername: '***'
chPassword: '***'
chCredentialsSecretNamespace: ""
chCredentialsSecretName: ""
chPort: 0
logtostderr: ""
alsologtostderr: ""
v: ""
stderrthreshold: ""
vmodule: ""
log_backtrace_at: ""
reconcileThreadsNumber: 0
reconcileWaitExclude: false
reconcileWaitInclude: false
includeIntoPropagationAnnotations: []
excludeFromPropagationAnnotations: []
includeIntoPropagationLabels: []
excludeFromPropagationLabels: []
appendScopeLabels: ""
terminationGracePeriod: 0
revisionHistoryLimit: 0
I0611 06:09:22.886437       1 config_manager.go:113] Final CHOP config:
I0611 06:09:22.886791       1 config_manager.go:114] 
runtime:
    configFilePath: /etc/clickhouse-operator/config.yaml
    configFolderPath: /etc/clickhouse-operator
    configCRNamespace: ""
    configCRName: ""
    configCRSources: []
    namespace: test
watch:
    namespaces:
        - test
clickhouse:
    configuration:
        file:
            path:
                common: /etc/clickhouse-operator/config.d
                host: /etc/clickhouse-operator/conf.d
                user: /etc/clickhouse-operator/users.d
            runtime:
                commonConfigFiles:
                    01-clickhouse-01-listen.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <!-- Listen wildcard address to allow accepting connections from other containers and host network. -->
                            <listen_host>::</listen_host>
                            <listen_host>0.0.0.0</listen_host>
                            <listen_try>1</listen_try>
                            <background_buffer_flush_schedule_pool_size>16</background_buffer_flush_schedule_pool_size>
                            <background_pool_size>16</background_pool_size>
                            <background_schedule_pool_size>128</background_schedule_pool_size>
                        </yandex>
                    01-clickhouse-02-logger.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <logger>
                                <!-- Possible levels: https://github.com/pocoproject/poco/blob/devel/Foundation/include/Poco/Logger.h#L439 -->
                                <level>debug</level>
                                <log>/var/log/clickhouse-server/clickhouse-server.log</log>
                                <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
                                <size>1000M</size>
                                <count>10</count>
                                <!-- Default behavior is autodetection (log to console if not daemon mode and is tty) -->
                                <console>1</console>
                            </logger>
                        </yandex>
                    01-clickhouse-03-query_log.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <query_log replace="1">
                                <database>system</database>
                                <table>query_log</table>
                                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                            </query_log>
                            <query_thread_log remove="1"/>
                        </yandex>
                    01-clickhouse-04-part_log.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <part_log replace="1">
                                <database>system</database>
                                <table>part_log</table>
                                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                            </part_log>
                        </yandex>
                    01-clickhouse-05-trace_log.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <trace_log replace="1">
                                <database>system</database>
                                <table>trace_log</table>
                                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                            </trace_log>
                        </yandex>
                usersConfigFiles:
                    01-clickhouse-operator-profile.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <!--
                        #
                        # Template parameters available:
                        #
                        -->
                        <yandex>
                            <!-- clickhouse-operator user is generated by the operator based on config.yaml in runtime -->
                            <profiles>
                                <clickhouse_operator>
                                    <log_queries>0</log_queries>
                                    <skip_unavailable_shards>1</skip_unavailable_shards>
                                    <http_connection_timeout>10</http_connection_timeout>
                                    <max_concurrent_queries_for_all_users>0</max_concurrent_queries_for_all_users>
                                    <os_thread_priority>0</os_thread_priority>
                                </clickhouse_operator>
                            </profiles>
                        </yandex>
                    02-clickhouse-default-profile.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                          <profiles>
                            <default>
                              <os_thread_priority>2</os_thread_priority>
                              <log_queries>1</log_queries>
                              <connect_timeout_with_failover_ms>1000</connect_timeout_with_failover_ms>
                              <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
                              <parallel_view_processing>1</parallel_view_processing>
                              <do_not_merge_across_partitions_select_final>1</do_not_merge_across_partitions_select_final>
                              <load_balancing>nearest_hostname</load_balancing>
                              <prefer_localhost_replica>0</prefer_localhost_replica>
                              <!-- materialize_ttl_recalculate_only>1</materialize_ttl_recalculate_only> 21.10 and above -->
                            </default>
                          </profiles>
                        </yandex>
        user:
            default:
                profile: default
                quota: default
                networksIP:
                    - ::1
                    - 127.0.0.1
                password: '***'
        network:
            hostRegexpTemplate: (chi-{chi}-[^.]+\d+-\d+|clickhouse\-{chi})\.{namespace}\.svc\.cluster\.local$
    configurationRestartPolicy:
        rules:
            - version: '*'
              rules:
                - settings/*: "yes"
                - settings/access_control_path: "no"
                - settings/dictionaries_config: "no"
                - settings/max_server_memory_*: "no"
                - settings/max_*_to_drop: "no"
                - settings/max_concurrent_queries: "no"
                - settings/models_config: "no"
                - settings/user_defined_executable_functions_config: "no"
                - settings/logger/*: "no"
                - settings/macros/*: "no"
                - settings/remote_servers/*: "no"
                - settings/user_directories/*: "no"
                - zookeeper/*: "yes"
                - files/*.xml: "yes"
                - files/config.d/*.xml: "yes"
                - files/config.d/*dict*.xml: "no"
                - profiles/default/background_*_pool_size: "yes"
                - profiles/default/max_*_for_server: "yes"
            - version: 21.*
              rules:
                - settings/logger: "yes"
    access:
        scheme: auto
        username: clickhouse_operator
        password: '***'
        secret:
            name: clickhouse-operator
            runtime:
                username: clickhouse_operator
                password: '***'
                fetched: true
                error: ""
        port: 8123
        timeouts:
            connect: 1s
            query: 4s
    metrics:
        timeouts:
            collect: 9s
template:
    chi:
        policy: ApplyOnNextReconcile
        path: /etc/clickhouse-operator/templates.d
reconcile:
    runtime:
        reconcileCHIsThreadsNumber: 10
        reconcileShardsThreadsNumber: 5
        reconcileShardsMaxConcurrencyPercent: 50
        threadsNumber: 1
    statefulSet:
        create:
            onFailure: ignore
        update:
            timeout: 300
            pollInterval: 5
            onFailure: abort
    host:
        wait:
            exclude: "true"
            queries: "true"
            include: "false"
annotation:
    include: []
    exclude: []
label:
    include: []
    exclude: []
    appendScope: "no"
    runtime:
        appendScope: false
statefulSet:
    revisionHistoryLimit: 10
pod:
    terminationGracePeriod: 30
logger:
    logtostderr: "true"
    alsologtostderr: "false"
    v: "1"
    stderrthreshold: ""
    vmodule: ""
    log_backtrace_at: ""
watchNamespaces: []
chCommonConfigsPath: ""
chHostConfigsPath: ""
chUsersConfigsPath: ""
chiTemplatesPath: ""
statefulSetUpdateTimeout: 0
statefulSetUpdatePollPeriod: 0
onStatefulSetCreateFailureAction: ""
onStatefulSetUpdateFailureAction: ""
chConfigUserDefaultProfile: ""
chConfigUserDefaultQuota: ""
chConfigUserDefaultNetworksIP: []
chConfigUserDefaultPassword: '***'
chConfigNetworksHostRegexpTemplate: ""
chScheme: ""
chUsername: '***'
chPassword: '***'
chCredentialsSecretNamespace: ""
chCredentialsSecretName: ""
chPort: 0
logtostderr: ""
alsologtostderr: ""
v: ""
stderrthreshold: ""
vmodule: ""
log_backtrace_at: ""
reconcileThreadsNumber: 0
reconcileWaitExclude: false
reconcileWaitInclude: false
includeIntoPropagationAnnotations: []
excludeFromPropagationAnnotations: []
includeIntoPropagationLabels: []
excludeFromPropagationLabels: []
appendScopeLabels: ""
terminationGracePeriod: 0
revisionHistoryLimit: 0
I0611 06:09:22.886807       1 chop.go:104] Log option 'logtostderr' change value from 'true' to 'true'
I0611 06:09:22.886815       1 chop.go:104] Log option 'alsologtostderr' change value from 'false' to 'false'
I0611 06:09:22.886819       1 chop.go:104] Log option 'v' change value from '1' to '1'
I0611 06:09:22.886828       1 chop.go:98] Additional log options applied
I0611 06:09:22.886833       1 thread_chi.go:63] initClickHouse():Config parsed:
I0611 06:09:22.887127       1 thread_chi.go:64] 
runtime:
    configFilePath: /etc/clickhouse-operator/config.yaml
    configFolderPath: /etc/clickhouse-operator
    configCRNamespace: ""
    configCRName: ""
    configCRSources: []
    namespace: test
watch:
    namespaces:
        - test
clickhouse:
    configuration:
        file:
            path:
                common: /etc/clickhouse-operator/config.d
                host: /etc/clickhouse-operator/conf.d
                user: /etc/clickhouse-operator/users.d
            runtime:
                commonConfigFiles:
                    01-clickhouse-01-listen.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <!-- Listen wildcard address to allow accepting connections from other containers and host network. -->
                            <listen_host>::</listen_host>
                            <listen_host>0.0.0.0</listen_host>
                            <listen_try>1</listen_try>
                            <background_buffer_flush_schedule_pool_size>16</background_buffer_flush_schedule_pool_size>
                            <background_pool_size>16</background_pool_size>
                            <background_schedule_pool_size>128</background_schedule_pool_size>
                        </yandex>
                    01-clickhouse-02-logger.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <logger>
                                <!-- Possible levels: https://github.com/pocoproject/poco/blob/devel/Foundation/include/Poco/Logger.h#L439 -->
                                <level>debug</level>
                                <log>/var/log/clickhouse-server/clickhouse-server.log</log>
                                <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
                                <size>1000M</size>
                                <count>10</count>
                                <!-- Default behavior is autodetection (log to console if not daemon mode and is tty) -->
                                <console>1</console>
                            </logger>
                        </yandex>
                    01-clickhouse-03-query_log.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <query_log replace="1">
                                <database>system</database>
                                <table>query_log</table>
                                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                            </query_log>
                            <query_thread_log remove="1"/>
                        </yandex>
                    01-clickhouse-04-part_log.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <part_log replace="1">
                                <database>system</database>
                                <table>part_log</table>
                                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                            </part_log>
                        </yandex>
                    01-clickhouse-05-trace_log.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                            <trace_log replace="1">
                                <database>system</database>
                                <table>trace_log</table>
                                <engine>Engine = MergeTree PARTITION BY event_date ORDER BY event_time TTL event_date + interval 30 day</engine>
                                <flush_interval_milliseconds>7500</flush_interval_milliseconds>
                            </trace_log>
                        </yandex>
                usersConfigFiles:
                    01-clickhouse-operator-profile.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <!--
                        #
                        # Template parameters available:
                        #
                        -->
                        <yandex>
                            <!-- clickhouse-operator user is generated by the operator based on config.yaml in runtime -->
                            <profiles>
                                <clickhouse_operator>
                                    <log_queries>0</log_queries>
                                    <skip_unavailable_shards>1</skip_unavailable_shards>
                                    <http_connection_timeout>10</http_connection_timeout>
                                    <max_concurrent_queries_for_all_users>0</max_concurrent_queries_for_all_users>
                                    <os_thread_priority>0</os_thread_priority>
                                </clickhouse_operator>
                            </profiles>
                        </yandex>
                    02-clickhouse-default-profile.xml: |
                        <!-- IMPORTANT -->
                        <!-- This file is auto-generated -->
                        <!-- Do not edit this file - all changes would be lost -->
                        <!-- Edit appropriate template in the following folder: -->
                        <!-- deploy/builder/templates-config -->
                        <!-- IMPORTANT -->
                        <yandex>
                          <profiles>
                            <default>
                              <os_thread_priority>2</os_thread_priority>
                              <log_queries>1</log_queries>
                              <connect_timeout_with_failover_ms>1000</connect_timeout_with_failover_ms>
                              <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
                              <parallel_view_processing>1</parallel_view_processing>
                              <do_not_merge_across_partitions_select_final>1</do_not_merge_across_partitions_select_final>
                              <load_balancing>nearest_hostname</load_balancing>
                              <prefer_localhost_replica>0</prefer_localhost_replica>
                              <!-- materialize_ttl_recalculate_only>1</materialize_ttl_recalculate_only> 21.10 and above -->
                            </default>
                          </profiles>
                        </yandex>
        user:
            default:
                profile: default
                quota: default
                networksIP:
                    - ::1
                    - 127.0.0.1
                password: '***'
        network:
            hostRegexpTemplate: (chi-{chi}-[^.]+\d+-\d+|clickhouse\-{chi})\.{namespace}\.svc\.cluster\.local$
    configurationRestartPolicy:
        rules:
            - version: '*'
              rules:
                - settings/*: "yes"
                - settings/access_control_path: "no"
                - settings/dictionaries_config: "no"
                - settings/max_server_memory_*: "no"
                - settings/max_*_to_drop: "no"
                - settings/max_concurrent_queries: "no"
                - settings/models_config: "no"
                - settings/user_defined_executable_functions_config: "no"
                - settings/logger/*: "no"
                - settings/macros/*: "no"
                - settings/remote_servers/*: "no"
                - settings/user_directories/*: "no"
                - zookeeper/*: "yes"
                - files/*.xml: "yes"
                - files/config.d/*.xml: "yes"
                - files/config.d/*dict*.xml: "no"
                - profiles/default/background_*_pool_size: "yes"
                - profiles/default/max_*_for_server: "yes"
            - version: 21.*
              rules:
                - settings/logger: "yes"
    access:
        scheme: auto
        username: clickhouse_operator
        password: '***'
        secret:
            name: clickhouse-operator
            runtime:
                username: clickhouse_operator
                password: '***'
                fetched: true
                error: ""
        port: 8123
        timeouts:
            connect: 1s
            query: 4s
    metrics:
        timeouts:
            collect: 9s
template:
    chi:
        policy: ApplyOnNextReconcile
        path: /etc/clickhouse-operator/templates.d
reconcile:
    runtime:
        reconcileCHIsThreadsNumber: 10
        reconcileShardsThreadsNumber: 5
        reconcileShardsMaxConcurrencyPercent: 50
        threadsNumber: 1
    statefulSet:
        create:
            onFailure: ignore
        update:
            timeout: 300
            pollInterval: 5
            onFailure: abort
    host:
        wait:
            exclude: "true"
            queries: "true"
            include: "false"
annotation:
    include: []
    exclude: []
label:
    include: []
    exclude: []
    appendScope: "no"
    runtime:
        appendScope: false
statefulSet:
    revisionHistoryLimit: 10
pod:
    terminationGracePeriod: 30
logger:
    logtostderr: "true"
    alsologtostderr: "false"
    v: "1"
    stderrthreshold: ""
    vmodule: ""
    log_backtrace_at: ""
watchNamespaces: []
chCommonConfigsPath: ""
chHostConfigsPath: ""
chUsersConfigsPath: ""
chiTemplatesPath: ""
statefulSetUpdateTimeout: 0
statefulSetUpdatePollPeriod: 0
onStatefulSetCreateFailureAction: ""
onStatefulSetUpdateFailureAction: ""
chConfigUserDefaultProfile: ""
chConfigUserDefaultQuota: ""
chConfigUserDefaultNetworksIP: []
chConfigUserDefaultPassword: '***'
chConfigNetworksHostRegexpTemplate: ""
chScheme: ""
chUsername: '***'
chPassword: '***'
chCredentialsSecretNamespace: ""
chCredentialsSecretName: ""
chPort: 0
logtostderr: ""
alsologtostderr: ""
v: ""
stderrthreshold: ""
vmodule: ""
log_backtrace_at: ""
reconcileThreadsNumber: 0
reconcileWaitExclude: false
reconcileWaitInclude: false
includeIntoPropagationAnnotations: []
excludeFromPropagationAnnotations: []
includeIntoPropagationLabels: []
excludeFromPropagationLabels: []
appendScopeLabels: ""
terminationGracePeriod: 0
revisionHistoryLimit: 0
I0611 06:09:22.887275       1 thread_chi.go:90] thread_chi.go:51:initClickHouse():end
2024-06-11T06:09:22Z	INFO	controller-runtime.metrics	Metrics server is starting to listen	{"addr": ":8080"}
I0611 06:09:22.889728       1 main.go:92] Starting keeper
I0611 06:09:22.889737       1 thread_chi_reconciler_metrics.go:49] thread_chi_reconciler_metrics.go:49:runClickHouseReconcilerMetricsExporter():start
I0611 06:09:22.889744       1 thread_chi_reconciler_metrics.go:52] runClickHouseReconcilerMetricsExporter():Starting operator metrics exporter
I0611 06:09:22.889757       1 thread_chi.go:94] thread_chi.go:94:runClickHouse():start
start serving metrics at: :9999/metrics
I0611 06:09:22.889816       1 thread_chi.go:98] runClickHouse():Starting CHI controller
I0611 06:09:22.889884       1 controller.go:471] Starting ClickHouseInstallation controller
2024-06-11T06:09:22Z	INFO	starting server	{"path": "/metrics", "kind": "metrics", "addr": "[::]:8080"}
I0611 06:09:22.889920       1 controller.go:930] waitForCacheSync():Syncing caches for ClickHouseInstallation controller
2024-06-11T06:09:22Z	INFO	Starting EventSource	{"controller": "clickhousekeeperinstallation", "controllerGroup": "clickhouse-keeper.altinity.com", "controllerKind": "ClickHouseKeeperInstallation", "source": "kind source: *v1.ClickHouseKeeperInstallation"}
2024-06-11T06:09:22Z	INFO	Starting EventSource	{"controller": "clickhousekeeperinstallation", "controllerGroup": "clickhouse-keeper.altinity.com", "controllerKind": "ClickHouseKeeperInstallation", "source": "kind source: *v1.StatefulSet"}
2024-06-11T06:09:22Z	INFO	Starting Controller	{"controller": "clickhousekeeperinstallation", "controllerGroup": "clickhouse-keeper.altinity.com", "controllerKind": "ClickHouseKeeperInstallation"}
I0611 06:09:22.990854       1 controller.go:935] waitForCacheSync():Caches are synced for ClickHouseInstallation controller
I0611 06:09:22.990895       1 labeler.go:83] OPERATOR_POD_NAMESPACE=test OPERATOR_POD_NAME=clickhouse-operator-69f675cf8f-86j5s
2024-06-11T06:09:22Z	INFO	Starting workers	{"controller": "clickhousekeeperinstallation", "controllerGroup": "clickhouse-keeper.altinity.com", "controllerKind": "ClickHouseKeeperInstallation", "worker count": 1}
I0611 06:09:23.009097       1 controller.go:503] Run():ClickHouseInstallation controller: starting workers number: 11
I0611 06:09:23.009116       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 1 out of 11
I0611 06:09:23.009134       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 2 out of 11
I0611 06:09:23.009143       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 3 out of 11
I0611 06:09:23.009151       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 4 out of 11
I0611 06:09:23.009162       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 5 out of 11
I0611 06:09:23.009171       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 6 out of 11
I0611 06:09:23.009182       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 7 out of 11
I0611 06:09:23.009192       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 8 out of 11
I0611 06:09:23.009201       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 9 out of 11
I0611 06:09:23.009207       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 10 out of 11
I0611 06:09:23.009212       1 controller.go:505] Run():ClickHouseInstallation controller: starting worker 11 out of 11
I0611 06:09:23.009220       1 controller.go:515] Run():ClickHouseInstallation controller: workers started
I0611 06:09:25.818019       1 worker-chit-reconciler.go:39] addChit():test/clickhouse-version:Add CHIT: test/clickhouse-version
I0611 06:09:25.867027       1 controller.go:572] ENQUEUE new ReconcileCHI cmd=add for test/test-001
I0611 06:09:33.010176       1 worker.go:431] worker.go:431:updateCHI():start:test/test-001
W0611 06:09:33.016721       1 warnings.go:70] metadata.finalizers: "finalizer.clickhouseinstallation.altinity.com": prefer a domain-qualified finalizer name to avoid accidental conflicts with other finalizer writers
I0611 06:09:33.016904       1 worker.go:435] updateCHI():test/test-001:finalizer installed, let's restart reconcile cycle. CHI: test/test-001
I0611 06:09:33.016954       1 worker.go:436] updateCHI():test/test-001:---------------------------------------------------------------------
I0611 06:09:33.016973       1 worker.go:437] worker.go:432:updateCHI():end:test/test-001
I0611 06:09:33.017495       1 controller.go:572] ENQUEUE new ReconcileCHI cmd=update for test/test-001
I0611 06:09:33.017636       1 worker.go:431] worker.go:431:updateCHI():start:test/test-001
I0611 06:09:33.017729       1 worker.go:439] updateCHI():test/test-001:finalizer in place, proceed to reconcile cycle. CHI: test/test-001
I0611 06:09:33.017769       1 worker.go:476] Operator IPs to process CHI: test-001. Previous:  Cur: 10.244.0.17
I0611 06:09:33.017778       1 worker.go:481] Operator IPs are different. Operator was restarted on another IP since previous reconcile of the CHI: test-001
I0611 06:09:33.018044       1 worker.go:564] test/test-001:logCHI non-normalized yet (native) old start--------------------------------------------:
non-normalized yet (native) old
logCHI kind: ""
apiversion: ""
metadata:
    name: test-001
    generatename: ""
    namespace: test
    selflink: ""
    uid: 2a304156-48c4-46fe-bd96-1e54541657f4
    resourceversion: "5924"
    generation: 1
    creationtimestamp: "2024-06-11T06:09:25Z"
    deletiontimestamp: null
    deletiongraceperiodseconds: null
    labels: {}
    annotations:
        kubectl.kubernetes.io/last-applied-configuration: |
            {"apiVersion":"clickhouse.altinity.com/v1","kind":"ClickHouseInstallation","metadata":{"annotations":{},"name":"test-001","namespace":"test"},"spec":{"configuration":{"clusters":[{"name":"single"}]}}}
    ownerreferences: []
    finalizers: []
    managedfields: []
spec:
    configuration:
        clusters:
            - name: single
 end--------------------------------------------
I0611 06:09:33.018284       1 worker.go:564] test/test-001:logCHI non-normalized yet (native) new start--------------------------------------------:
non-normalized yet (native) new
logCHI kind: ClickHouseInstallation
apiversion: clickhouse.altinity.com/v1
metadata:
    name: test-001
    generatename: ""
    namespace: test
    selflink: ""
    uid: 2a304156-48c4-46fe-bd96-1e54541657f4
    resourceversion: "5936"
    generation: 1
    creationtimestamp: "2024-06-11T06:09:25Z"
    deletiontimestamp: null
    deletiongraceperiodseconds: null
    labels: {}
    annotations:
        kubectl.kubernetes.io/last-applied-configuration: |
            {"apiVersion":"clickhouse.altinity.com/v1","kind":"ClickHouseInstallation","metadata":{"annotations":{},"name":"test-001","namespace":"test"},"spec":{"configuration":{"clusters":[{"name":"single"}]}}}
    ownerreferences: []
    finalizers:
        - finalizer.clickhouseinstallation.altinity.com
    managedfields: []
spec:
    configuration:
        clusters:
            - name: single
 end--------------------------------------------
I0611 06:09:33.018323       1 worker-chi-reconciler.go:53] reconcileCHI():test/test-001:isAfterFinalizerInstalled - continue reconcile-1
I0611 06:09:33.018346       1 worker-chi-reconciler.go:59] worker-chi-reconciler.go:59:reconcileCHI():start:test/test-001
I0611 06:09:33.018525       1 worker-chi-reconciler.go:65] reconcileCHI():test/test-001:Changing OLD to Normalized COMPLETED: test/test-001
I0611 06:09:33.018549       1 worker-chi-reconciler.go:71] reconcileCHI():test/test-001:has NO ancestor, use empty CHI as a base for reconcile. CHI: test/test-001
I0611 06:09:33.018565       1 worker-chi-reconciler.go:75] reconcileCHI():test/test-001:Normalized OLD CHI: test/test-001
I0611 06:09:33.018595       1 chi.go:38] prepareListOfTemplates():/:Found applicable templates num: 0
I0611 06:09:33.018612       1 chi.go:82] ApplyCHITemplates():/:Applied templates num: 0
I0611 06:09:33.018877       1 worker.go:339] //d9618abc-24ac-465e-a447-f9151bad12c8:IPs of the CHI normalizer /: len: 0 []
I0611 06:09:33.018909       1 chi.go:38] prepareListOfTemplates():/:Found applicable templates num: 0
I0611 06:09:33.018929       1 chi.go:82] ApplyCHITemplates():/:Applied templates num: 0
I0611 06:09:33.019134       1 worker-chi-reconciler.go:78] reconcileCHI():test/test-001:Normalized NEW CHI: test/test-001
I0611 06:09:33.019159       1 chi.go:38] prepareListOfTemplates():test/test-001:Found applicable templates num: 0
I0611 06:09:33.019169       1 chi.go:82] ApplyCHITemplates():test/test-001:Applied templates num: 0
I0611 06:09:33.021854       1 worker.go:339] test/test-001/80a0acf6-508c-4691-a473-b0c0da7c68bb:IPs of the CHI normalizer test/test-001: len: 0 []
I0611 06:09:33.021889       1 chi.go:38] prepareListOfTemplates():test/test-001:Found applicable templates num: 0
I0611 06:09:33.021903       1 chi.go:82] ApplyCHITemplates():test/test-001:Applied templates num: 0
I0611 06:09:33.022437       1 worker.go:564] //24843494-3ba0-47dd-b9a6-1b19466bdb8d:logCHI normalized old start--------------------------------------------:
normalized old
logCHI kind: ClickHouseInstallation
apiversion: clickhouse.altinity.com/v1
spec:
    taskID: 24843494-3ba0-47dd-b9a6-1b19466bdb8d
    stop: "False"
    troubleshoot: "False"
    templating:
        policy: manual
    reconciling:
        policy: unspecified
        configMapPropagationTimeout: 10
        cleanup:
            unknownObjects:
                statefulSet: Delete
                pvc: Delete
                configMap: Delete
                service: Delete
            reconcileFailedObjects:
                statefulSet: Retain
                pvc: Retain
                configMap: Retain
                service: Retain
    defaults:
        replicasUseFQDN: "False"
        storageManagement: {}
    configuration:
        users: {}
 end--------------------------------------------
I0611 06:09:33.023316       1 worker.go:564] test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:logCHI normalized new start--------------------------------------------:
normalized new
logCHI kind: ClickHouseInstallation
apiversion: clickhouse.altinity.com/v1
metadata:
    name: test-001
    generatename: ""
    namespace: test
    selflink: ""
    uid: 2a304156-48c4-46fe-bd96-1e54541657f4
    resourceversion: "5936"
    generation: 1
    creationtimestamp: "2024-06-11T06:09:25Z"
    deletiontimestamp: null
    deletiongraceperiodseconds: null
    labels: {}
    annotations: {}
    ownerreferences: []
    finalizers:
        - finalizer.clickhouseinstallation.altinity.com
    managedfields: []
spec:
    taskID: 793b37e1-ec0d-4b8c-967b-6e7f97cc3305
    stop: "False"
    troubleshoot: "False"
    templating:
        policy: manual
    reconciling:
        policy: unspecified
        configMapPropagationTimeout: 10
        cleanup:
            unknownObjects:
                statefulSet: Delete
                pvc: Delete
                configMap: Delete
                service: Delete
            reconcileFailedObjects:
                statefulSet: Retain
                pvc: Retain
                configMap: Retain
                service: Retain
    defaults:
        replicasUseFQDN: "False"
        storageManagement: {}
    configuration:
        users: {}
        clusters:
            - name: single
              schemaPolicy:
                replica: All
                shard: All
              layout:
                shardsCount: 1
                replicasCount: 1
                shards:
                    - name: "0"
                      internalReplication: "False"
                      replicasCount: 1
                      replicas:
                        - name: 0-0
                          tcpPort: 9000
                          httpPort: 8123
                          interserverHTTPPort: 9009
                replicas:
                    - name: "0"
                      shardsCount: 1
                      shards:
                        - name: 0-0
                          tcpPort: 9000
                          httpPort: 8123
                          interserverHTTPPort: 9009
 end--------------------------------------------
I0611 06:09:33.023860       1 worker.go:574] ActionPlan start---------------------------------------------:
Diff start -------------------------
modified spec items num: 3
diff item [0]:'.TaskID' = '"793b37e1-ec0d-4b8c-967b-6e7f97cc3305"'
diff item [1]:'.Configuration.Users.m["default/networks/host_regexp"].scalar' = '"(chi-test-001-[^.]+\\d+-\\d+|clickhouse\\-test-001)\\.test\\.svc\\.cluster\\.local$"'
diff item [2]:'.Configuration.Clusters' = '[0x40002a2a00]'
Diff end -------------------------
modified finalizer:
Diff start -------------------------
modified finalizers num: 1
diff item [0]:'.metadata.finalizers' = '[]string{
  "finalizer.clickhouseinstallation.altinity.com",
}'
Diff end -------------------------

ActionPlan end---------------------------------------------
I0611 06:09:33.025939       1 worker-chi-reconciler.go:89] reconcileCHI():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:ActionPlan has actions - continue reconcile
I0611 06:09:33.033220       1 worker.go:663] markReconcileStart():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:reconcile started, task id: 793b37e1-ec0d-4b8c-967b-6e7f97cc3305
I0611 06:09:33.046571       1 worker.go:820] FOUND host: ns:test|chi:test-001|clu:single|sha:0|rep:0|host:0-0
I0611 06:09:33.046610       1 worker.go:844] RemoteServersGeneratorOptions: exclude hosts: [], attributes: status: , add: true, remove: false, modify: false, found: false, exclude: true
I0611 06:09:33.049736       1 worker.go:1343] createConfigMap():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Create ConfigMap test/chi-test-001-common-configd
I0611 06:09:33.429113       1 worker.go:1343] createConfigMap():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Create ConfigMap test/chi-test-001-common-usersd
I0611 06:09:33.842931       1 service.go:86] CreateServiceCluster():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:test/cluster-test-001-single
I0611 06:09:33.848205       1 worker-chi-reconciler.go:827] PDB created: test/test-001-single
I0611 06:09:33.848248       1 worker-chi-reconciler.go:554] not found ReconcileShardsAndHostsOptionsCtxKey, use empty opts
I0611 06:09:33.848260       1 worker-chi-reconciler.go:568] starting first shard separately
I0611 06:09:33.848353       1 worker-chi-reconciler.go:684] reconcileHost():Reconcile Host start. Host: 0-0 ClickHouse version running: host is a new one, version is not not applicable
I0611 06:09:34.241778       1 worker.go:1001] worker.go:1001:excludeHost():start:exclude host start
I0611 06:09:34.241832       1 worker.go:1152] shouldExcludeHost():Host is the only host in the shard (means no replication), no need to exclude. Host/shard/cluster: 0/0/single
I0611 06:09:34.241844       1 worker.go:1005] worker.go:1002:excludeHost():end:exclude host end
I0611 06:09:34.241861       1 worker.go:1020] worker.go:1020:completeQueries():start:complete queries start
I0611 06:09:34.241890       1 worker.go:1214] shouldWaitQueries():No need to wait for queries to complete, host is a new one. Host/shard/cluster: 0/0/single
I0611 06:09:34.241912       1 worker.go:1027] worker.go:1021:completeQueries():end:complete queries end
I0611 06:09:34.432223       1 worker.go:1343] createConfigMap():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Create ConfigMap test/chi-test-001-deploy-confd-single-0-0
I0611 06:09:34.838391       1 worker-chi-reconciler.go:716] reconcileHost():Reconcile PVCs and check possible data loss for host: 0-0
I0611 06:09:34.838461       1 worker-chi-reconciler.go:406] worker-chi-reconciler.go:406:reconcileHostStatefulSet():start:reconcile StatefulSet start
I0611 06:09:34.840440       1 worker-chi-reconciler.go:412] reconcileHostStatefulSet():Reconcile host: 0-0. ClickHouse version: host is a new one, version is not not applicable
I0611 06:09:34.840472       1 worker.go:127] shouldForceRestartHost():Host is new, no restart applicable. Host: 0-0
I0611 06:09:34.840489       1 worker-chi-reconciler.go:425] reconcileHostStatefulSet():Reconcile host: 0-0. Reconcile StatefulSet
I0611 06:09:34.841530       1 worker.go:1704] updateStatefulSet():Update StatefulSet(test/chi-test-001-single-0-0) - started
I0611 06:09:35.236388       1 worker.go:1652] waitConfigMapPropagation():No need to wait for ConfigMap propagation - no changes in ConfigMap
I0611 06:09:35.236426       1 worker.go:1742] updateStatefulSet():Update StatefulSet(test/chi-test-001-single-0-0) switch from Update to Recreate
I0611 06:09:35.643467       1 worker-chi-reconciler.go:966] Cur StatefulSet is not available, nothing to compare to
I0611 06:09:35.643530       1 deleter.go:127] deleteStatefulSet():test/chi-test-001-single-0-0
I0611 06:09:35.645431       1 deleter.go:134] NEUTRAL not found StatefulSet test/chi-test-001-single-0-0
I0611 06:09:35.645509       1 worker.go:1596] createStatefulSet():Create StatefulSet test/chi-test-001-single-0-0 - started
I0611 06:09:36.041158       1 creator.go:35] createStatefulSet()
I0611 06:09:36.041194       1 creator.go:44] Create StatefulSet test/chi-test-001-single-0-0
I0611 06:09:36.054477       1 worker.go:266] processReconcilePod():test/chi-test-001-single-0-0-0:Add Pod. test/chi-test-001-single-0-0-0
I0611 06:09:41.438264       1 poller.go:138] Poll():test/chi-test-001-single-0-0:OK test/chi-test-001-single-0-0
I0611 06:09:51.464166       1 poller.go:138] Poll():test/chi-test-001-single-0-0:OK test/chi-test-001-single-0-0
I0611 06:09:51.478916       1 worker.go:1615] createStatefulSet():Create StatefulSet test/chi-test-001-single-0-0 - completed
I0611 06:09:51.489664       1 worker-chi-reconciler.go:445] worker-chi-reconciler.go:407:reconcileHostStatefulSet():end:reconcile StatefulSet end
I0611 06:09:51.490009       1 worker-chi-reconciler.go:907] reconcileService():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Service: test/chi-test-001-single-0-0 not found. err: service "chi-test-001-single-0-0" not found
I0611 06:09:51.491371       1 deleter.go:322] deleteServiceIfExists():test/chi-test-001-single-0-0:Not Found Service: test/chi-test-001-single-0-0 err: services "chi-test-001-single-0-0" not found
I0611 06:09:51.494663       1 worker.go:1480] createService():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:OK Create Service: test/chi-test-001-single-0-0
I0611 06:09:51.502762       1 worker-chi-reconciler.go:922] reconcileService():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Service reconcile successful: test/chi-test-001-single-0-0
I0611 06:09:51.502785       1 worker-chi-reconciler.go:461] reconcileHostService():DONE Reconcile service of the host: 0-0
I0611 06:09:51.502829       1 cluster.go:84] Run query on: chi-test-001-single-0-0.test.svc.cluster.local of [chi-test-001-single-0-0.test.svc.cluster.local]
I0611 06:09:51.506893       1 worker-chi-reconciler.go:349] getHostClickHouseVersion():Get ClickHouse version on host: 0-0 version: 24.5.1.1763
I0611 06:09:51.506916       1 poller.go:138] Poll():test/0-0:OK test/0-0
I0611 06:09:51.506934       1 worker-chi-reconciler.go:753] reconcileHost():Check host for ClickHouse availability before migrating tables. Host: 0-0 ClickHouse version running: 24.5.1.1763
I0611 06:09:51.506964       1 worker.go:908] migrateTables():No need to add tables on host 0 to shard 0 in cluster single
I0611 06:09:51.506981       1 worker.go:1057] includeHost():Include into cluster host 0 shard 0 cluster single
I0611 06:09:51.506988       1 worker.go:1124] includeHostIntoClickHouseCluster():going to include host 0 shard 0 cluster single
I0611 06:09:51.506998       1 worker.go:844] RemoteServersGeneratorOptions: exclude hosts: [], attributes: status: , add: true, remove: false, modify: false, found: false, exclude: true
I0611 06:09:51.509157       1 worker.go:1315] updateConfigMap():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Update ConfigMap test/chi-test-001-common-configd
I0611 06:09:52.270869       1 cluster.go:84] Run query on: chi-test-001-single-0-0.test.svc.cluster.local of [chi-test-001-single-0-0.test.svc.cluster.local]
I0611 06:09:52.276757       1 worker-chi-reconciler.go:349] getHostClickHouseVersion():Get ClickHouse version on host: 0-0 version: 24.5.1.1763
I0611 06:09:52.276795       1 poller.go:138] Poll():test/0-0:OK test/0-0
I0611 06:09:52.276833       1 worker-chi-reconciler.go:776] reconcileHost():Reconcile Host completed. Host: 0-0 ClickHouse version running: 24.5.1.1763
I0611 06:09:52.666842       1 worker-chi-reconciler.go:797] reconcileHost():[now: 2024-06-11 06:09:52.666820166 +0000 UTC m=+29.793572352] ProgressHostsCompleted: 1 of 1
I0611 06:09:53.273463       1 worker-chi-reconciler.go:907] reconcileService():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Service: test/clickhouse-test-001 not found. err: service "clickhouse-test-001" not found
I0611 06:09:53.462629       1 deleter.go:322] deleteServiceIfExists():test/clickhouse-test-001:Not Found Service: test/clickhouse-test-001 err: services "clickhouse-test-001" not found
I0611 06:09:53.666494       1 worker.go:1480] createService():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:OK Create Service: test/clickhouse-test-001
I0611 06:09:54.077901       1 worker-chi-reconciler.go:922] reconcileService():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Service reconcile successful: test/clickhouse-test-001
I0611 06:09:54.077937       1 worker-chi-reconciler.go:581] Starting rest of shards on workers: 1
I0611 06:09:54.269197       1 worker.go:1315] updateConfigMap():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Update ConfigMap test/chi-test-001-common-configd
I0611 06:09:54.684858       1 worker-deleter.go:43] clean():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:remove items scheduled for deletion
I0611 06:09:55.082335       1 worker-deleter.go:46] clean():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:List of objects which have failed to reconcile:
I0611 06:09:55.082387       1 worker-deleter.go:47] clean():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:List of successfully reconciled objects:
ConfigMap: test/chi-test-001-common-configd
ConfigMap: test/chi-test-001-common-usersd
ConfigMap: test/chi-test-001-deploy-confd-single-0-0
PDB: test/test-001-single
StatefulSet: test/chi-test-001-single-0-0
Service: test/chi-test-001-single-0-0
Service: test/clickhouse-test-001
I0611 06:09:55.866940       1 worker-deleter.go:50] clean():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Existing objects:
StatefulSet: test/chi-test-001-single-0-0
ConfigMap: test/chi-test-001-common-configd
ConfigMap: test/chi-test-001-common-usersd
ConfigMap: test/chi-test-001-deploy-confd-single-0-0
Service: test/clickhouse-test-001
Service: test/chi-test-001-single-0-0
PDB: test/test-001-single
I0611 06:09:55.867054       1 worker-deleter.go:52] clean():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:Non-reconciled objects:
I0611 06:09:55.867095       1 worker-deleter.go:68] worker-deleter.go:68:dropReplicas():start:test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:drop replicas based on AP
I0611 06:09:55.867153       1 worker-deleter.go:80] worker-deleter.go:80:dropReplicas():end:test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:processed replicas: 0
I0611 06:09:55.867201       1 worker.go:640] addCHIToMonitoring():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:add CHI to monitoring
I0611 06:09:56.283393       1 worker.go:595] worker.go:595:waitForIPAddresses():start:test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:wait for IP addresses to be assigned to all pods
I0611 06:09:56.284788       1 controller.go:617] OK update watch (test/test-001): {"namespace":"test","name":"test-001","labels":null,"annotations":{},"clusters":[{"name":"single","hosts":[{"name":"0-0","hostname":"chi-test-001-single-0-0.test.svc.cluster.local","tcpPort":9000,"httpPort":8123}]}]}
I0611 06:09:56.286800       1 worker.go:600] test/test-001:all IP addresses are in place
I0611 06:09:56.286848       1 worker.go:673] worker.go:673:finalizeReconcileAndMarkCompleted():start:test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:finalize reconcile
I0611 06:09:56.289606       1 chi.go:38] prepareListOfTemplates():test/test-001:Found applicable templates num: 0
I0611 06:09:56.289625       1 chi.go:82] ApplyCHITemplates():test/test-001:Applied templates num: 0
I0611 06:09:56.290003       1 worker.go:677] test/test-001/07d1e789-9e99-4626-8880-5f5f75e6a79f:updating endpoints for CHI-2 test-001
I0611 06:09:56.464411       1 worker.go:679] test/test-001/07d1e789-9e99-4626-8880-5f5f75e6a79f:IPs of the CHI-2 finalize reconcile test/test-001: len: 1 [10.244.0.18]
I0611 06:09:56.467128       1 chi.go:38] prepareListOfTemplates():test/test-001:Found applicable templates num: 0
I0611 06:09:56.467172       1 chi.go:82] ApplyCHITemplates():test/test-001:Applied templates num: 0
I0611 06:09:56.468131       1 worker.go:683] test/test-001/586df8b5-a13b-4343-8372-ddeda4949995:Update users IPS-2
I0611 06:09:56.671628       1 worker.go:1315] updateConfigMap():test/test-001/586df8b5-a13b-4343-8372-ddeda4949995:Update ConfigMap test/chi-test-001-common-usersd
I0611 06:09:57.271385       1 worker.go:707] finalizeReconcileAndMarkCompleted():test/test-001/793b37e1-ec0d-4b8c-967b-6e7f97cc3305:reconcile completed successfully, task id: 793b37e1-ec0d-4b8c-967b-6e7f97cc3305
I0611 06:09:57.681659       1 worker-chi-reconciler.go:134] worker-chi-reconciler.go:60:reconcileCHI():end:test/test-001
I0611 06:09:57.681730       1 worker.go:469] worker.go:432:updateCHI():end:test/test-001
I0611 06:10:11.843609       1 controller.go:572] ENQUEUE new ReconcileCHI cmd=update for test/test-001
I0611 06:10:11.843763       1 worker.go:431] worker.go:431:updateCHI():start:test/test-001
I0611 06:10:11.843808       1 worker.go:439] updateCHI():test/test-001:finalizer in place, proceed to reconcile cycle. CHI: test/test-001
I0611 06:10:11.853983       1 worker-deleter.go:619] deleteCHI():test/test-001:CRD: /clickhouseinstallations.clickhouse.altinity.com is not being deleted, operator will delete child resources
I0611 06:10:11.855766       1 chi.go:38] prepareListOfTemplates():test/test-001:Found applicable templates num: 0
I0611 06:10:11.855786       1 chi.go:82] ApplyCHITemplates():test/test-001:Applied templates num: 0
I0611 06:10:11.856149       1 worker-deleter.go:284] deleteCHIProtocol():test/test-001/f2ff0288-b304-46c8-b3fa-e4f81dd16f86:Delete CHI started
I0611 06:10:11.871391       1 deleter.go:306] deleteServiceCHI():test/test-001/f2ff0288-b304-46c8-b3fa-e4f81dd16f86:test/clickhouse-test-001
I0611 06:10:11.871972       1 controller.go:632] OK delete watch (test/test-001)
I0611 06:10:11.874020       1 deleter.go:329] deleteServiceIfExists():test/clickhouse-test-001:OK delete Service: test/clickhouse-test-001
I0611 06:10:11.874061       1 cluster.go:84] Run query on: chi-test-001-single-0-0.test.svc.cluster.local of [chi-test-001-single-0-0.test.svc.cluster.local]
I0611 06:10:11.877718       1 schemer.go:46] HostSyncTables():Sync tables: [] as []
I0611 06:10:11.877780       1 worker-deleter.go:565] deleteCluster():Delete cluster: test/single - started
I0611 06:10:11.886716       1 deleter.go:293] deleteServiceCluster():test/cluster-test-001-single
I0611 06:10:11.887592       1 deleter.go:322] deleteServiceIfExists():test/cluster-test-001-single:Not Found Service: test/cluster-test-001-single err: services "cluster-test-001-single" not found
I0611 06:10:11.887617       1 worker-deleter.go:531] deleteShard():Delete shard: test/0 - started
I0611 06:10:11.901591       1 deleter.go:280] deleteServiceShard():test/shard-test-001-single-0
I0611 06:10:12.059000       1 deleter.go:322] deleteServiceIfExists():test/shard-test-001-single-0:Not Found Service: test/shard-test-001-single-0 err: services "shard-test-001-single-0" not found
I0611 06:10:12.059059       1 worker-deleter.go:469] deleteHost():Delete host: single/0-0 - started
I0611 06:10:12.481953       1 cluster.go:84] Run query on: chi-test-001-single-0-0.test.svc.cluster.local of [chi-test-001-single-0-0.test.svc.cluster.local]
I0611 06:10:12.486710       1 schemer.go:123] HostDropTables():Drop tables: [] as []
I0611 06:10:12.486794       1 worker-deleter.go:442] deleteTables():Deleted tables on host: 0-0 replica: 0 to shard: 0 in cluster: single
I0611 06:10:12.874304       1 deleter.go:34] deleter.go:34:deleteHost():start:single/0-0
I0611 06:10:12.874359       1 deleter.go:127] deleteStatefulSet():test/chi-test-001-single-0-0
I0611 06:10:18.466452       1 poller.go:138] Poll():test/chi-test-001-single-0-0:OK test/chi-test-001-single-0-0
I0611 06:10:18.894471       1 worker.go:275] processReconcilePod():test/chi-test-001-single-0-0-0:Delete Pod. test/chi-test-001-single-0-0-0
I0611 06:10:23.475745       1 poller.go:138] Poll():test/chi-test-001-single-0-0:OK test/chi-test-001-single-0-0
I0611 06:10:23.480036       1 deleter.go:155] OK delete StatefulSet test/chi-test-001-single-0-0
I0611 06:10:38.484395       1 poller.go:108] cache synced
I0611 06:10:38.485995       1 deleter.go:233] deleteConfigMap():test/chi-test-001-deploy-confd-single-0-0
I0611 06:10:38.488901       1 deleter.go:236] OK delete ConfigMap test/chi-test-001-deploy-confd-single-0-0
I0611 06:10:38.488948       1 deleter.go:267] deleteServiceHost():test/chi-test-001-single-0-0
I0611 06:10:38.492842       1 deleter.go:329] deleteServiceIfExists():test/chi-test-001-single-0-0:OK delete Service: test/chi-test-001-single-0-0
I0611 06:10:38.492874       1 deleter.go:42] deleter.go:42:deleteHost():end:single/0-0
I0611 06:10:38.502403       1 worker-deleter.go:505] deleteHost():Delete host: single/0-0 - completed
I0611 06:10:38.512023       1 worker-deleter.go:545] deleteShard():Delete shard: test/0 - completed
I0611 06:10:38.520021       1 worker-deleter.go:585] deleteCluster():Delete cluster: test/single - completed
I0611 06:10:38.888964       1 deleter.go:69] test/test-001/f2ff0288-b304-46c8-b3fa-e4f81dd16f86:OK delete ConfigMap test/chi-test-001-common-configd
I0611 06:10:39.096361       1 deleter.go:79] test/test-001/f2ff0288-b304-46c8-b3fa-e4f81dd16f86:OK delete ConfigMap test/chi-test-001-common-usersd
I0611 06:10:39.096460       1 worker-deleter.go:327] deleteCHIProtocol():test/test-001/f2ff0288-b304-46c8-b3fa-e4f81dd16f86:Delete CHI completed
I0611 06:10:39.518567       1 worker.go:449] worker.go:432:updateCHI():end:test/test-001
I0611 06:10:44.926403       1 worker-chit-reconciler.go:67] deleteChit():test/clickhouse-version
I0611 06:10:44.926414       1 worker-chit-reconciler.go:70] deleteChit():test/clickhouse-version:Delete CHIT: test/clickhouse-version
I0611 06:10:44.929143       1 controller.go:517] Run():ClickHouseInstallation controller: shutting down workers
I0611 06:10:44.929172       1 thread_chi.go:100] thread_chi.go:95:runClickHouse():end
I0611 06:10:44.929179       1 worker.go:176] shutdown request
2024-06-11T06:10:44Z	INFO	Stopping and waiting for non leader election runnables
I0611 06:10:44.929204       1 worker.go:176] shutdown request
I0611 06:10:44.929210       1 worker.go:176] shutdown request
I0611 06:10:44.929216       1 worker.go:176] shutdown request
I0611 06:10:44.929219       1 worker.go:176] shutdown request
I0611 06:10:44.929222       1 worker.go:176] shutdown request
I0611 06:10:44.929226       1 worker.go:176] shutdown request
I0611 06:10:44.929228       1 worker.go:176] shutdown request
I0611 06:10:44.929232       1 worker.go:176] shutdown request
I0611 06:10:44.929239       1 worker.go:176] shutdown request
I0611 06:10:44.929250       1 worker.go:176] shutdown request
2024-06-11T06:10:44Z	INFO	shutting down server	{"path": "/metrics", "kind": "metrics", "addr": "[::]:8080"}
2024-06-11T06:10:44Z	INFO	Stopping and waiting for leader election runnables
2024-06-11T06:10:44Z	INFO	Shutdown signal received, waiting for all workers to finish	{"controller": "clickhousekeeperinstallation", "controllerGroup": "clickhouse-keeper.altinity.com", "controllerKind": "ClickHouseKeeperInstallation"}
2024-06-11T06:10:44Z	INFO	All workers finished	{"controller": "clickhousekeeperinstallation", "controllerGroup": "clickhouse-keeper.altinity.com", "controllerKind": "ClickHouseKeeperInstallation"}
2024-06-11T06:10:44Z	INFO	Stopping and waiting for caches
2024-06-11T06:10:44Z	INFO	Stopping and waiting for webhooks
2024-06-11T06:10:44Z	INFO	Wait completed, proceeding to shutdown the manager
I0611 06:10:44.929535       1 main.go:95] Starting keeper OK
